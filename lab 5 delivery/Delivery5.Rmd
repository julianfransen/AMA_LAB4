---
title: 'Delivery 5: AMA'
author: "Marc Falc√≥n Barau, Julian Fransen, Victor Garcia Pizarro"
date: "2024-11-24"
output:
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r include=FALSE}
setwd("~/uni_folder/AMA/AMA_LAB4/lab 5 delivery")
```

# Bandwidth choice for the local Poisson regression

In this part, we modify the `h.cv.sm.binomial` and `loglik.CV` functions to obtain a bandwidth choice method for the local Poisson regression based on the loo-CV estimation. We will use the formulas given by the instructions: 

For leave-one-out cross-validation estimation of the expected log-likelihood of an independent observation, when using $h$ as bandwidth, we use
\[
\ell_{CV}(h)
=\frac{1}{n}\sum_{i=1}^{n} \log\left( \widehat{\Pr}_h^{\tiny(-i)}(Y=y_i|X=x_i)\right),
\]
where $\widehat{\Pr}_h^{\tiny(-i)}(Y=y_i|X=x_i)$ is an estimation of
\[
\Pr(Y=y_i|X=x_i)=e^{-\lambda_i} \frac{\lambda_i^{y_i}}{y_i!},
\]
and 
\[
\lambda_i=\mathbb{E}(Y|X=x_i)
\]

```{r}
# Here we changed the name to poisson
h.cv.sm.poisson <- function(x,y,rg.h=NULL,l.h=10,method=loglik.CV){
   cv.h <- numeric(l.h)
   if (is.null(rg.h)){
      hh <- c(h.select(x,y,method="cv"),
              h.select(x,y,method="aicc"))#,hcv(x,y))
      rg.h <- range(hh)*c(1/1.1, 1.5)
   }
   i <- 0
   gr.h <- exp( seq(log(rg.h[1]), log(rg.h[2]), l=l.h))
   for (h in gr.h){
      i <- i+1
      cv.h[i] <- method(x,y,h)
   }
   return(list(h = gr.h, 
               cv.h = cv.h, 
               h.cv = gr.h[which.max(cv.h)])) # Here we changed the min to max
}

loglik.CV <- function(x, y, h) {
  n <- length(y)
  mean(sapply(1:n, function(i) {
    # Estimate lambda for the i-th observation
    lambda_i <- sm.poisson(x = x[-i], y = y[-i], h = h, eval.points = x[i], display = "none")$estimate
    # Compute log-likelihood for the i-th observation
    log(dpois(y[i], lambda = lambda_i)) # Use the dpois function to get the probabilites
  }))
}
```

In the code you can see that we copied the code for `h.cv.sm.poisson` completely from the `h.cv.sm.binomial` found in the lab. The only thing we changed, besides the name, is the `min` to`max` for `h.cv`, since we are trying to maximize the log likelihood, not minimize. However, the code for `loglik.CV` is changed significantly. We calculate the $\lambda_i$ based on the formulas, where we use the `sm.poisson` function to obtain the estimate. Then the mean is used, which is equivalent to the sum divided by n part of the formula. By using sapply, we make sure that for every value of h the function is applied for all $i \in n$. 

# Local Poisson regression for Country Development Data

Now we apply the modified functions to the country development dataset to find the optimal value of h, the smoothing parameter. The target value is `le.fm.r`, which is the rounded value of `le.fm` and the explanatory variable is `Life.expec`. This code is again based on the code seen in lab. 

```{r include=FALSE}
# Load data and libraries
countries<-read.csv2(file="HDI.2017.subset.csv",row.names = 1)
attach(countries)
library(sm)

# Round the float value so we can use Poisson modelling
countries$le.fm.r <-  round(countries$le.fm)
x <- countries$Life.expec
y <- countries$le.fm.r
```

For the range of h we intinally use h $\in [1, 10]$. This was partly based on theory and partly based on empirical analysis: the values of h should be dependent on the range of explanatory variable. This idea agrees with our experiment, because when we scale the data we see that the optimal value for h is different. First we show the results without scaling.

```{r}
h_min <- 1; h_max <- 10
par(mfrow=c(1,2))
h.CV.loglik <- h.cv.sm.poisson(x,y,rg.h=c(h_min,h_max),method=loglik.CV)
plot(h.CV.loglik$h,h.CV.loglik$cv.h)
lines(h.CV.loglik$h,h.CV.loglik$cv.h)

h_min <- 2.5; h_max <- 3.0
h.CV.loglik <- h.cv.sm.poisson(x,y,rg.h=c(h_min,h_max),method=loglik.CV)
plot(h.CV.loglik$h,h.CV.loglik$cv.h)
lines(h.CV.loglik$h,h.CV.loglik$cv.h)
h_optimal <- h.CV.loglik$h.cv; h.CV.loglik$h.cv
```

On the first plot, we use h $\in [1, 10]$, and we see that $h^*$ lies somewhere around 3. So we run the algorithm again to be more accurate, which you can see in the second plot. We find that the optimal value for h is 2.71 with a loo-CV error of 2.03. 

Now we show that scaling affects the $h^*$:
```{r}
x_scaled <- scale(x)
h_min <- 0.1; h_max <- 0.6
h.CV.loglik <- h.cv.sm.poisson(x_scaled,y,rg.h=c(h_min,h_max),method=loglik.CV)
plot(h.CV.loglik$h,h.CV.loglik$cv.h)
lines(h.CV.loglik$h,h.CV.loglik$cv.h)
h.CV.loglik$h.cv
```

After scaling, $h^* = 0.33$, which is approximately 10 times smaller than the solution found without scaling. 



```{r}
h_optimal <- h.CV.loglik$h.cv
# Here we fit the local Poisson regression model
local_poisson_fit <- sm.poisson(x = x, y = y, h = h_optimal, display = "none")
plot(x, y, pch = 16, xlab = "Life Expectancy", ylab = "Rounded Life Expectancy (le.fm.r)", col = "blue",
     main = "Local Poisson Regression Fit")
lines(local_poisson_fit$eval.points, local_poisson_fit$estimate, col = "red", lwd = 2)
```

Above you can see the fitted Poisson model in blue and the data points in red. Even though the plotted line is continuous, a Poisson only predicts counts, i.e. integer numbers. 